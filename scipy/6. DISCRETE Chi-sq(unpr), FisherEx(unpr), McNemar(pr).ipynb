{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"which_test.gif\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chi-Square Test\n",
    "\n",
    "Without other qualification, 'chi-squared test' often is used as short for Pearson's chi-squared test. The chi-squared test is used to determine whether there is a significant difference between the expected frequencies and the observed frequencies in one or more categories.\n",
    "\n",
    "Chi-squared tests are often constructed from a sum of squared errors, or through the sample variance. Test statistics that follow a chi-squared distribution arise from an assumption of independent normally distributed data, which is valid in many cases due to the central limit theorem. A chi-squared test can be used to attempt rejection of the null hypothesis that the data are independent.\n",
    "\n",
    "Poker machine that deals cards\n",
    "\n",
    "Hearts 441, Spades 404, Diamonds 402, Clubs 353, Sum (1600)\n",
    "\n",
    "Could it be that these suits are equally likely or are these discrepancies too much to be random?\n",
    "\n",
    "# $ \\chi^2 = \\sum \\frac {(O - E)^2}{E} $\n",
    "\n",
    "$ O $ Observed values\n",
    "\n",
    "$ E $ Expected values\n",
    "\n",
    "$ H_0: P_{Hearts} = P_{Spades} = P_{Diamonds} = P_{Clubs} $\n",
    "\n",
    "$ H_1: P_{Hearts} \\neq P_{Spades} \\neq P_{Diamonds} \\neq P_{Clubs} $\n",
    "\n",
    "$ df = n.  of groups - 1 = 3 $\n",
    "\n",
    "$ ChiSquare_{STAT} $ = 9.77\n",
    "\n",
    "$ ChiSquare_{CRIT} $ = 7.81\n",
    "\n",
    "<img src=\"chi.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/V4SRgabFbz0\" frameborder=\"0\" gesture=\"media\" allow=\"encrypted-media\" allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML('<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/V4SRgabFbz0\" frameborder=\"0\" gesture=\"media\" allow=\"encrypted-media\" allowfullscreen></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ChiSquare in Scipy\n",
    "\n",
    "##### scipy.stats.chisquare(f_obs, f_exp=None, ddof=0, axis=0)\n",
    "\n",
    "Calculate a one-way chi square test.\n",
    "\n",
    "The chi square test tests the null hypothesis that the categorical data has the given frequencies.\n",
    "\n",
    "- Parameters:\t\n",
    "    - f_obs : array_like\n",
    "        - Observed frequencies in each category.\n",
    "    - f_exp : array_like, optional\n",
    "        - Expected frequencies in each category. By default the categories are assumed to be equally likely.\n",
    "    - ddof : int, optional\n",
    "        - “Delta degrees of freedom”: adjustment to the degrees of freedom for the p-value. The p-value is computed using a chi-squared distribution with k - 1 - ddof degrees of freedom, where k is the number of observed frequencies. The default value of ddof is 0.\n",
    "    - axis : int or None, optional\n",
    "        - The axis of the broadcast result of f_obs and f_exp along which to apply the test. If axis is None, all values in f_obs are treated as a single data set. Default is 0.\n",
    "\n",
    "- Returns:\t\n",
    "    - chisq : float or ndarray\n",
    "        - The chi-squared test statistic. The value is a float if axis is None or f_obs and f_exp are 1-D.\n",
    "    - p : float or ndarray\n",
    "        - The p-value of the test. The value is a float if ddof and the return value chisq are scalars.\n",
    "\n",
    "This test is invalid when the observed or expected frequencies in each category are too small. A typical rule is that all of the observed and expected frequencies should be at least 5.\n",
    "\n",
    "The default degrees of freedom, k-1, are for the case when no parameters of the distribution are estimated. If p parameters are estimated by efficient maximum likelihood then the correct degrees of freedom are k-1-p. If the parameters are estimated in a different way, then the dof can be between k-1-p and k-1. However, it is also possible that the asymptotic distribution is not a chisquare, in which case this test is not appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Power_divergenceResult(statistic=2.0, pvalue=0.84914503608460956)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# When just f_obs is given, it is assumed that the expected frequencies are uniform and given by the mean of the observed frequencies.\n",
    "from scipy.stats import chisquare\n",
    "chisquare([16, 18, 16, 14, 12, 12])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fishers Exact test\n",
    "\n",
    "For example, a sample of teenagers might be divided into male and female on the one hand, and those that are and are not currently studying for a statistics exam on the other. We hypothesize, for example, that the proportion of studying individuals is higher among the women than among the men, and we want to test whether any difference of proportions that we observe is significant. The data might look like this:\n",
    "\n",
    "<img src=\"fish1.png\">\n",
    "\n",
    "\n",
    "The question we ask about these data is: knowing that 10 of these 24 teenagers are studiers, and that 12 of the 24 are female, and assuming the null hypothesis that men and women are equally likely to study, what is the probability that these 10 studiers would be so unevenly distributed between the women and the men? If we were to choose 10 of the teenagers at random, what is the probability that 9 or more of them would be among the 12 women, and only 1 or fewer from among the 12 men?\n",
    "\n",
    "Before we proceed with the Fisher test, we first introduce some notations. We represent the cells by the letters a, b, c and d, call the totals across rows and columns marginal totals, and represent the grand total by n. So the table now looks like this:\n",
    "\n",
    "<img src=\"fish2.png\">\n",
    "\n",
    "Fisher showed that the probability of obtaining any such set of values was given by the hypergeometric distribution:\n",
    "\n",
    "$ p = \\frac{ \\displaystyle{{a+b}\\choose{a}} \\displaystyle{{c+d}\\choose{c}} }{ \\displaystyle{{n}\\choose{a+c}} } = \\frac{(a+b)!~(c+d)!~(a+c)!~(b+d)!}{a!~~b!~~c!~~d!~~n!} $\n",
    "\n",
    "$ p = { {\\tbinom{10}{1}} {\\tbinom{14}{11}} }/{ {\\tbinom{24}{12}} } = \\tfrac{10!~14!~12!~12!}{1!~9!~11!~3!~24!} $\n",
    "\n",
    "$ = 0.001346076 $\n",
    "\n",
    "The formula above gives the exact hypergeometric probability of observing this particular arrangement of the data, assuming the given marginal totals, on the null hypothesis that men and women are equally likely to be studiers. To put it another way, if we assume that the probability that a man is a studier is $p$, the probability that a woman is a studier is also $p$, and we assume that both men and women enter our sample independently of whether or not they are studiers, then this hypergeometric formula gives the conditional probability of observing the values a, b, c, d in the four cells, conditionally on the observed marginals (i.e., assuming the row and column totals shown in the margins of the table are given). This remains true even if men enter our sample with different probabilities than women. The requirement is merely that the two classification characteristics—gender, and studier (or not)—are not associated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/I9KsLCc-eiQ\" frameborder=\"0\" gesture=\"media\" allow=\"encrypted-media\" allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML('<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/I9KsLCc-eiQ\" frameborder=\"0\" gesture=\"media\" allow=\"encrypted-media\" allowfullscreen></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fishers Exact test in Scipy\n",
    "\n",
    "##### scipy.stats.fisher_exact(table, alternative='two-sided')\n",
    "\n",
    "Performs a Fisher exact test on a 2x2 contingency table.\n",
    "\n",
    "- Parameters:\t\n",
    "    - table : array_like of ints\n",
    "        - A 2x2 contingency table. Elements should be non-negative integers.\n",
    "    - alternative : {‘two-sided’, ‘less’, ‘greater’}, optional\n",
    "        - Which alternative hypothesis to the null hypothesis the test uses. Default is ‘two-sided’.\n",
    "\n",
    "- Returns:\t\n",
    "    - oddsratio : float\n",
    "        - This is prior odds ratio and not a posterior estimate.\n",
    "    - p_value : float\n",
    "        - P-value, the probability of obtaining a distribution at least as extreme as the one that was actually observed, assuming that the null hypothesis is true.\n",
    "\n",
    "The calculated odds ratio is different from the one R uses. This scipy implementation returns the (more common) “unconditional Maximum Likelihood Estimate”, while R uses the “conditional Maximum Likelihood Estimate”.\n",
    "\n",
    "For tables with large numbers, the (inexact) chi-square test implemented in the function chi2_contingency can also be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.034965034965034947"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Say we spend a few days counting whales and sharks in the Atlantic and Indian oceans. In the Atlantic ocean we find 8 whales and 1 shark, in the Indian ocean 2 whales and 5 sharks. Then our contingency table is:\n",
    "\n",
    "        Atlantic  Indian\n",
    "whales     8        2\n",
    "sharks     1        5\n",
    "\n",
    "We use this table to find the p-value:\n",
    "\"\"\"\n",
    "\n",
    "import scipy.stats as stats\n",
    "oddsratio, pvalue = stats.fisher_exact([[8, 2], [1, 5]])\n",
    "pvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# McNemar test\n",
    "\n",
    "In statistics, McNemar's test is a statistical test used on paired nominal data. It is applied to 2 × 2 contingency tables with a dichotomous trait, with matched pairs of subjects, to determine whether the row and column marginal frequencies are equal (that is, whether there is \"marginal homogeneity\")\n",
    "\n",
    "The test is applied to a 2 × 2 contingency table, which tabulates the outcomes of two tests on a sample of n subjects, as follows.\n",
    "\n",
    "<img src=\"mc1.png\">\n",
    "\n",
    "$a and d$ are concodant pairs.\n",
    "\n",
    "$b anc c$ are the concordant pairs.\n",
    "\n",
    "Thus the null and alternative hypotheses are:\n",
    "\n",
    "$ H_0: P_b = P_c $\n",
    "\n",
    "$ H_1: P_b \\neq P_c $\n",
    "\n",
    "Here pa, etc., denote the theoretical probability of occurrences in cells with the corresponding label.\n",
    "\n",
    "The McNemar test statistic is:\n",
    "\n",
    "# $ \\chi^2 = {(b-c)^2 \\over b+c} $\n",
    "\n",
    "Under the null hypothesis, with a sufficiently large number of discordants (cells b and c), $\\chi^{2}$ has a chi-squared distribution with 1 degree of freedom. If the $\\chi^{2}$ result is significant, this provides sufficient evidence to reject the null hypothesis, in favour of the alternative hypothesis that pb ≠ pc, which would mean that the marginal proportions are significantly different from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/XpO3zaQAgS0\" frameborder=\"0\" gesture=\"media\" allow=\"encrypted-media\" allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML('<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/XpO3zaQAgS0\" frameborder=\"0\" gesture=\"media\" allow=\"encrypted-media\" allowfullscreen></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# McNemar test in Scipy\n",
    "\n",
    "##### scipy.stats.chi2_contingency(observed, correction=True, lambda_=None)\n",
    "\n",
    "Chi-square test of independence of variables in a contingency table.\n",
    "\n",
    "This function computes the chi-square statistic and p-value for the hypothesis test of independence of the observed frequencies in the contingency table observed. The expected frequencies are computed based on the marginal sums under the assumption of independence; see scipy.stats.contingency.expected_freq. The number of degrees of freedom is (expressed using numpy functions and attributes):\n",
    "\n",
    "`dof = observed.size - sum(observed.shape) + observed.ndim - 1`\n",
    "\n",
    "- Parameters:\t\n",
    "    - observed : array_like\n",
    "        - The contingency table. The table contains the observed frequencies (i.e. number of occurrences) in each category. In the two-dimensional case, the table is often described as an “R x C table”.\n",
    "    - correction : bool, optional\n",
    "        - If True, and the degrees of freedom is 1, apply Yates’ correction for continuity. The effect of the correction is to adjust each observed value by 0.5 towards the corresponding expected value.\n",
    "    - lambda_ : float or str, optional.\n",
    "\n",
    "By default, the statistic computed in this test is Pearson’s chi-squared statistic. lambda_ allows a statistic from the Cressie-Read power divergence family to be used instead. See power_divergence for details.\n",
    "\n",
    "- Returns:\t\n",
    "    - chi2 : float\n",
    "        - The test statistic.\n",
    "    - p : float\n",
    "        - The p-value of the test\n",
    "    - dof : int\n",
    "        - Degrees of freedom\n",
    "    - expected : ndarray, same shape as observed\n",
    "        - The expected frequencies, based on the marginal sums of the table.\n",
    "\n",
    "An often quoted guideline for the validity of this calculation is that the test should be used only if the observed and expected frequency in each cell is at least 5.\n",
    "\n",
    "This is a test for the independence of different categories of a population. The test is only meaningful when the dimension of observed is two or more. Applying the test to a one-dimensional table will always result in expected equal to observed and a chi-square statistic equal to 0.\n",
    "\n",
    "This function does not handle masked arrays, because the calculation does not make sense with missing values.\n",
    "\n",
    "Like stats.chisquare, this function computes a chi-square statistic; the convenience this function provides is to figure out the expected frequencies and degrees of freedom from the given contingency table. If these were already known, and if the Yates’ correction was not required, one could use stats.chisquare. That is, if one calls:\n",
    "\n",
    "`chi2, p, dof, ex = chi2_contingency(obs, correction=False)`\n",
    "\n",
    "then the following is true:\n",
    "\n",
    "`(chi2, p) == stats.chisquare(obs.ravel(), f_exp=ex.ravel(),\n",
    "                             ddof=obs.size - 1 - dof)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.7777777777777777, 0.24935220877729622, 2, array([[ 12.,  12.,  16.],\n",
       "        [ 18.,  18.,  24.]]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import chi2_contingency\n",
    "obs = np.array([[10, 10, 20], [20, 20, 20]])\n",
    "chi2_contingency(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
