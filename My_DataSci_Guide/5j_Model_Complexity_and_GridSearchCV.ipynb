{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter selection, Validation, and Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most models have parameters that influence how complex a model they can learn. Remember using `KNeighborsRegressor`.\n",
    "If we change the number of neighbors we consider, we get a smoother and smoother prediction:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/plot_kneigbors_regularization.png\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above figure, we see fits for three different values of ``n_neighbors``.\n",
    "For ``n_neighbors=2``, the data is overfit, the model is too flexible and can adjust too much to the noise in the training data. For ``n_neighbors=20``, the model is not flexible enough, and can not model the variation in the data appropriately.\n",
    "\n",
    "In the middle, for ``n_neighbors = 5``, we have found a good mid-point. It fits\n",
    "the data fairly well, and does not suffer from the overfit or underfit\n",
    "problems seen in the figures on either side. What we would like is a\n",
    "way to quantitatively identify overfit and underfit, and optimize the\n",
    "hyperparameters (in this case, the polynomial degree d) in order to\n",
    "determine the best algorithm.\n",
    "\n",
    "We trade off remembering too much about the particularities and noise of the training data vs. not modeling enough of the variability. This is a trade-off that needs to be made in basically every machine learning application and is a central concept, called bias-variance-tradeoff or \"overfitting vs underfitting\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/overfitting_underfitting_cartoon.svg\" width=\"100%\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters, Over-fitting, and Under-fitting\n",
    "\n",
    "Unfortunately, there is no general rule how to find the sweet spot, and so machine learning practitioners have to find the best trade-off of model-complexity and generalization by trying several hyperparameter settings. Hyperparameters are the internal knobs or tuning parameters of a machine learning algorithm (in contrast to model parameters that the algorithm learns from the training data -- for example, the weight coefficients of a linear regression model); the number of *k* in K-nearest neighbors is such a hyperparameter.\n",
    "\n",
    "Most commonly this \"hyperparameter tuning\" is done using a brute force search, for example over multiple values of ``n_neighbors``:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_neighbors: 1, average score: 0.531799\n",
      "n_neighbors: 3, average score: 0.682766\n",
      "n_neighbors: 5, average score: 0.725138\n",
      "n_neighbors: 10, average score: 0.715716\n",
      "n_neighbors: 20, average score: 0.652454\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "# generate toy dataset:\n",
    "x = np.linspace(-3, 3, 100)\n",
    "rng = np.random.RandomState(42)\n",
    "y = np.sin(4 * x) + x + rng.normal(size=len(x))\n",
    "X = x[:, np.newaxis]\n",
    "\n",
    "cv = KFold(shuffle=True)\n",
    "\n",
    "# for each parameter setting do cross-validation:\n",
    "for n_neighbors in [1, 3, 5, 10, 20]:\n",
    "    scores = cross_val_score(KNeighborsRegressor(n_neighbors=n_neighbors), X, y, cv=cv)\n",
    "    print(\"n_neighbors: %d, average score: %f\" % (n_neighbors, np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a function in scikit-learn, called ``validation_plot`` to reproduce the cartoon figure above. It plots one parameter, such as the number of neighbors, against training and validation error (using cross-validation):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10fa562b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import validation_curve\n",
    "n_neighbors = [1, 3, 5, 10, 20, 50]\n",
    "train_scores, test_scores = validation_curve(KNeighborsRegressor(), X, y, param_name=\"n_neighbors\",\n",
    "                                             param_range=n_neighbors, cv=cv)\n",
    "plt.plot(n_neighbors, train_scores.mean(axis=1), 'b', label=\"train accuracy\")\n",
    "plt.plot(n_neighbors, test_scores.mean(axis=1), 'g', label=\"test accuracy\")\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Number of neighbors')\n",
    "plt.xlim([50, 0])\n",
    "plt.legend(loc=\"best\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    Note that many neighbors mean a \"smooth\" or \"simple\" model, so the plot uses a reverted x axis.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If multiple parameters are important, like the parameters ``C`` and ``gamma`` in an ``SVM`` (more about that later), all possible combinations are tried:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 0.001000, gamma: 0.001000, average score: -0.076508\n",
      "C: 0.001000, gamma: 0.010000, average score: -0.052433\n",
      "C: 0.001000, gamma: 0.100000, average score: -0.000661\n",
      "C: 0.001000, gamma: 1.000000, average score: -0.000530\n",
      "C: 0.010000, gamma: 0.001000, average score: -0.018375\n",
      "C: 0.010000, gamma: 0.010000, average score: -0.017605\n",
      "C: 0.010000, gamma: 0.100000, average score: 0.022207\n",
      "C: 0.010000, gamma: 1.000000, average score: 0.032637\n",
      "C: 0.100000, gamma: 0.001000, average score: -0.116044\n",
      "C: 0.100000, gamma: 0.010000, average score: 0.143997\n",
      "C: 0.100000, gamma: 0.100000, average score: 0.494121\n",
      "C: 0.100000, gamma: 1.000000, average score: 0.481979\n",
      "C: 1.000000, gamma: 0.001000, average score: 0.195875\n",
      "C: 1.000000, gamma: 0.010000, average score: 0.528022\n",
      "C: 1.000000, gamma: 0.100000, average score: 0.645266\n",
      "C: 1.000000, gamma: 1.000000, average score: 0.706728\n",
      "C: 10.000000, gamma: 0.001000, average score: 0.568211\n",
      "C: 10.000000, gamma: 0.010000, average score: 0.628548\n",
      "C: 10.000000, gamma: 0.100000, average score: 0.664240\n",
      "C: 10.000000, gamma: 1.000000, average score: 0.754567\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# each parameter setting do cross-validation:\n",
    "for C in [0.001, 0.01, 0.1, 1, 10]:\n",
    "    for gamma in [0.001, 0.01, 0.1, 1]:\n",
    "        scores = cross_val_score(SVR(C=C, gamma=gamma), X, y, cv=cv)\n",
    "        print(\"C: %f, gamma: %f, average score: %f\" % (C, gamma, np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As this is such a very common pattern, there is a built-in class for this in scikit-learn, ``GridSearchCV``. ``GridSearchCV`` takes a dictionary that describes the parameters that should be tried and a model to train.\n",
    "\n",
    "The grid of parameters is defined as a dictionary, where the keys are the parameters and the values are the settings to be tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10], 'gamma': [0.001, 0.01, 0.1, 1]}\n",
    "\n",
    "grid = GridSearchCV(SVR(), param_grid=param_grid, cv=cv, verbose=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the great things about GridSearchCV is that it is a *meta-estimator*. It takes an estimator like SVR above, and creates a new estimator, that behaves exactly the same - in this case, like a regressor.\n",
    "So we can call ``fit`` on it, to train it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "[CV] C=0.001, gamma=0.001 ............................................\n",
      "[CV]  C=0.001, gamma=0.001, score=-0.010747509952212075, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.001 ............................................\n",
      "[CV]  C=0.001, gamma=0.001, score=-0.0007744736331982693, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.001 ............................................\n",
      "[CV]  C=0.001, gamma=0.001, score=-0.039652033213778415, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.01 .............................................\n",
      "[CV] . C=0.001, gamma=0.01, score=-0.008827248785798103, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.01 .............................................\n",
      "[CV] . C=0.001, gamma=0.01, score=0.0014863019549855585, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.01 .............................................\n",
      "[CV] .. C=0.001, gamma=0.01, score=-0.03760876937776447, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.1 ..............................................\n",
      "[CV] . C=0.001, gamma=0.1, score=-0.0003801352643022504, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.1 ..............................................\n",
      "[CV] ... C=0.001, gamma=0.1, score=0.011529476815300477, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.1 ..............................................\n",
      "[CV] .. C=0.001, gamma=0.1, score=-0.028709243797072407, total=   0.0s\n",
      "[CV] C=0.001, gamma=1 ................................................\n",
      "[CV] ... C=0.001, gamma=1, score=-0.0016834748384682021, total=   0.0s\n",
      "[CV] C=0.001, gamma=1 ................................................\n",
      "[CV] ..... C=0.001, gamma=1, score=0.010358082412147529, total=   0.0s\n",
      "[CV] C=0.001, gamma=1 ................................................\n",
      "[CV] .... C=0.001, gamma=1, score=-0.030583743417201163, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.001 .............................................\n",
      "[CV] . C=0.01, gamma=0.001, score=-0.008632361438128733, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.001 .............................................\n",
      "[CV] .. C=0.01, gamma=0.001, score=0.001705878719116538, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.001 .............................................\n",
      "[CV] .. C=0.01, gamma=0.001, score=-0.03739907952374666, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.01 ..............................................\n",
      "[CV] ... C=0.01, gamma=0.01, score=0.010942279719866721, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.01 ..............................................\n",
      "[CV] .... C=0.01, gamma=0.01, score=0.02351061016636047, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.01 ..............................................\n",
      "[CV] .. C=0.01, gamma=0.01, score=-0.017117055708961715, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.1 ...............................................\n",
      "[CV] ..... C=0.01, gamma=0.1, score=0.09052030675097722, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.1 ...............................................\n",
      "[CV] ..... C=0.01, gamma=0.1, score=0.11266950883999238, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.1 ...............................................\n",
      "[CV] ..... C=0.01, gamma=0.1, score=0.07505098310185077, total=   0.0s\n",
      "[CV] C=0.01, gamma=1 .................................................\n",
      "[CV] ....... C=0.01, gamma=1, score=0.07807647511148386, total=   0.0s\n",
      "[CV] C=0.01, gamma=1 .................................................\n",
      "[CV] ....... C=0.01, gamma=1, score=0.10372506065035414, total=   0.0s\n",
      "[CV] C=0.01, gamma=1 .................................................\n",
      "[CV] ...... C=0.01, gamma=1, score=0.061263033492107814, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV] ... C=0.1, gamma=0.001, score=0.013058048481004779, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV] ... C=0.1, gamma=0.001, score=0.025593638377727213, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV] .. C=0.1, gamma=0.001, score=-0.015051484101598069, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV] ..... C=0.1, gamma=0.01, score=0.16014923168969375, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV] ..... C=0.1, gamma=0.01, score=0.19931552793570143, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV] ..... C=0.1, gamma=0.01, score=0.16742627873510985, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV] ...... C=0.1, gamma=0.1, score=0.44560865922280646, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV] ....... C=0.1, gamma=0.1, score=0.5458380022933574, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV] ........ C=0.1, gamma=0.1, score=0.568977316347017, total=   0.0s\n",
      "[CV] C=0.1, gamma=1 ..................................................\n",
      "[CV] ......... C=0.1, gamma=1, score=0.4317110404657685, total=   0.0s\n",
      "[CV] C=0.1, gamma=1 ..................................................\n",
      "[CV] ......... C=0.1, gamma=1, score=0.5476490084849023, total=   0.0s\n",
      "[CV] C=0.1, gamma=1 ..................................................\n",
      "[CV] ......... C=0.1, gamma=1, score=0.5397282109250368, total=   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] ...... C=1, gamma=0.001, score=0.17327550993287677, total=   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] ...... C=1, gamma=0.001, score=0.21314415232083203, total=   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] ...... C=1, gamma=0.001, score=0.18445404512067032, total=   0.0s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] ........ C=1, gamma=0.01, score=0.5521294506598063, total=   0.0s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] ........ C=1, gamma=0.01, score=0.5814505197354087, total=   0.0s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] ........ C=1, gamma=0.01, score=0.6294721455340226, total=   0.0s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] .......... C=1, gamma=0.1, score=0.621287023383382, total=   0.0s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] ......... C=1, gamma=0.1, score=0.6279883285087552, total=   0.0s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] .......... C=1, gamma=0.1, score=0.777346701092043, total=   0.0s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] ............ C=1, gamma=1, score=0.673478556598379, total=   0.0s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] ........... C=1, gamma=1, score=0.6587114345156977, total=   0.0s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] ........... C=1, gamma=1, score=0.8086634849383227, total=   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ...... C=10, gamma=0.001, score=0.5462608041172174, total=   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ...... C=10, gamma=0.001, score=0.5709003952487832, total=   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ....... C=10, gamma=0.001, score=0.639477018413008, total=   0.0s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] ....... C=10, gamma=0.01, score=0.5819725289286539, total=   0.0s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] ....... C=10, gamma=0.01, score=0.6080566656854358, total=   0.0s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] ....... C=10, gamma=0.01, score=0.7225297615374088, total=   0.0s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] ........ C=10, gamma=0.1, score=0.6209652173421079, total=   0.0s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] ......... C=10, gamma=0.1, score=0.614231944642847, total=   0.0s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] ........ C=10, gamma=0.1, score=0.7833592263856316, total=   0.0s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] .......... C=10, gamma=1, score=0.7288309038860415, total=   0.0s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] .......... C=10, gamma=1, score=0.7189798667402396, total=   0.0s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] .......... C=10, gamma=1, score=0.8124565464574833, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=3, random_state=None, shuffle=True),\n",
       "       error_score='raise',\n",
       "       estimator=SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'C': [0.001, 0.01, 0.1, 1, 10], 'gamma': [0.001, 0.01, 0.1, 1]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What ``fit`` does is a bit more involved then what we did above. First, it runs the same loop with cross-validation, to find the best parameter combination.\n",
    "Once it has the best combination, it runs fit again on all data passed to fit (without cross-validation), to built a single new model using the best parameter setting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, as with all models, we can use ``predict`` or ``score``:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.79762875, -1.74054091, -1.71412904, -1.72272347, -1.76880247,\n",
       "       -1.8527208 , -1.97255382, -2.12407501, -2.30087676, -2.49463429,\n",
       "       -2.695503  , -2.89262935, -3.07474705, -3.23082299, -3.35071314,\n",
       "       -3.42578612, -3.44947391, -3.41771237, -3.32924127, -3.18574205,\n",
       "       -2.9918017 , -2.75470244, -2.48404785, -2.19124658, -1.88888388,\n",
       "       -1.59001819, -1.30744475, -1.05297034, -0.8367425 , -0.66667333,\n",
       "       -0.54799235, -0.4829551 , -0.4707249 , -0.50743515, -0.58642852,\n",
       "       -0.69865919, -0.83323456, -0.97806438, -1.12057877, -1.24847261,\n",
       "       -1.35043139, -1.41679516, -1.44012026, -1.41560488, -1.3413525 ,\n",
       "       -1.21845724, -1.05090633, -0.84530623, -0.61045003, -0.35675398,\n",
       "       -0.09559933,  0.16137852,  0.40300817,  0.61926205,  0.80185531,\n",
       "        0.94472644,  1.04437082,  1.10000798,  1.11357463,  1.08954695,\n",
       "        1.03460678,  0.95717608,  0.86685224,  0.7737823 ,  0.68801751,\n",
       "        0.61888941,  0.57444669,  0.56098656,  0.58270777,  0.64150352,\n",
       "        0.73690334,  0.86616306,  1.02449275,  1.20540425,  1.40115266,\n",
       "        1.60324152,  1.80295801,  1.99190412,  2.16249073,  2.3083654 ,\n",
       "        2.42474939,  2.50866621,  2.55905134,  2.57674055,  2.56434191,\n",
       "        2.52600389,  2.46709789,  2.39383845,  2.31286721,  2.23082834,\n",
       "        2.15396216,  2.0877418 ,  2.03657355,  2.00357681,  1.99045342,\n",
       "        1.99745004,  2.02341108,  2.06591373,  2.12147209,  2.18579347])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "You can inspect the best parameters found by ``GridSearchCV`` in the ``best_params_`` attribute, and the best score in the ``best_score_`` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7531765236765027\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'gamma': 1}\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But you can investigate the performance and much more for each set of parameter values by accessing the `cv_results_` attributes. The `cv_results_` attribute is a dictionary where each key is a string and each value is array. It can therefore be used to make a pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.utils.deprecation.DeprecationDict"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time', 'param_C', 'param_gamma', 'params', 'split0_test_score', 'split1_test_score', 'split2_test_score', 'mean_test_score', 'std_test_score', 'rank_test_score', 'split0_train_score', 'split1_train_score', 'split2_train_score', 'mean_train_score', 'std_train_score'])\n"
     ]
    }
   ],
   "source": [
    "print(grid.cv_results_.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002118</td>\n",
       "      <td>0.001080</td>\n",
       "      <td>-0.016995</td>\n",
       "      <td>-0.004808</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 0.001, 'gamma': 0.001}</td>\n",
       "      <td>20</td>\n",
       "      <td>-0.010748</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>-0.000774</td>\n",
       "      <td>-0.001962</td>\n",
       "      <td>-0.039652</td>\n",
       "      <td>-0.012704</td>\n",
       "      <td>0.001512</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>0.016416</td>\n",
       "      <td>0.005655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001380</td>\n",
       "      <td>0.001229</td>\n",
       "      <td>-0.014922</td>\n",
       "      <td>-0.002782</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 0.001, 'gamma': 0.01}</td>\n",
       "      <td>19</td>\n",
       "      <td>-0.008827</td>\n",
       "      <td>0.002340</td>\n",
       "      <td>0.001486</td>\n",
       "      <td>0.000386</td>\n",
       "      <td>-0.037609</td>\n",
       "      <td>-0.011071</td>\n",
       "      <td>0.000886</td>\n",
       "      <td>0.000639</td>\n",
       "      <td>0.016472</td>\n",
       "      <td>0.005916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000579</td>\n",
       "      <td>0.000402</td>\n",
       "      <td>-0.005799</td>\n",
       "      <td>0.006044</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 0.001, 'gamma': 0.1}</td>\n",
       "      <td>16</td>\n",
       "      <td>-0.000380</td>\n",
       "      <td>0.011885</td>\n",
       "      <td>0.011529</td>\n",
       "      <td>0.010117</td>\n",
       "      <td>-0.028709</td>\n",
       "      <td>-0.003870</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.016801</td>\n",
       "      <td>0.007048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001067</td>\n",
       "      <td>0.000696</td>\n",
       "      <td>-0.007247</td>\n",
       "      <td>0.004850</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1</td>\n",
       "      <td>{'C': 0.001, 'gamma': 1}</td>\n",
       "      <td>17</td>\n",
       "      <td>-0.001683</td>\n",
       "      <td>0.011057</td>\n",
       "      <td>0.010358</td>\n",
       "      <td>0.008433</td>\n",
       "      <td>-0.030584</td>\n",
       "      <td>-0.004939</td>\n",
       "      <td>0.000463</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>0.017103</td>\n",
       "      <td>0.007004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000981</td>\n",
       "      <td>0.000379</td>\n",
       "      <td>-0.014714</td>\n",
       "      <td>-0.002576</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 0.01, 'gamma': 0.001}</td>\n",
       "      <td>18</td>\n",
       "      <td>-0.008632</td>\n",
       "      <td>0.002543</td>\n",
       "      <td>0.001706</td>\n",
       "      <td>0.000636</td>\n",
       "      <td>-0.037399</td>\n",
       "      <td>-0.010906</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.016473</td>\n",
       "      <td>0.005942</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score param_C  \\\n",
       "0       0.002118         0.001080        -0.016995         -0.004808   0.001   \n",
       "1       0.001380         0.001229        -0.014922         -0.002782   0.001   \n",
       "2       0.000579         0.000402        -0.005799          0.006044   0.001   \n",
       "3       0.001067         0.000696        -0.007247          0.004850   0.001   \n",
       "4       0.000981         0.000379        -0.014714         -0.002576    0.01   \n",
       "\n",
       "  param_gamma                        params  rank_test_score  \\\n",
       "0       0.001  {'C': 0.001, 'gamma': 0.001}               20   \n",
       "1        0.01   {'C': 0.001, 'gamma': 0.01}               19   \n",
       "2         0.1    {'C': 0.001, 'gamma': 0.1}               16   \n",
       "3           1      {'C': 0.001, 'gamma': 1}               17   \n",
       "4       0.001   {'C': 0.01, 'gamma': 0.001}               18   \n",
       "\n",
       "   split0_test_score  split0_train_score  split1_test_score  \\\n",
       "0          -0.010748            0.000243          -0.000774   \n",
       "1          -0.008827            0.002340           0.001486   \n",
       "2          -0.000380            0.011885           0.011529   \n",
       "3          -0.001683            0.011057           0.010358   \n",
       "4          -0.008632            0.002543           0.001706   \n",
       "\n",
       "   split1_train_score  split2_test_score  split2_train_score  std_fit_time  \\\n",
       "0           -0.001962          -0.039652           -0.012704      0.001512   \n",
       "1            0.000386          -0.037609           -0.011071      0.000886   \n",
       "2            0.010117          -0.028709           -0.003870      0.000104   \n",
       "3            0.008433          -0.030584           -0.004939      0.000463   \n",
       "4            0.000636          -0.037399           -0.010906      0.000215   \n",
       "\n",
       "   std_score_time  std_test_score  std_train_score  \n",
       "0        0.000329        0.016416         0.005655  \n",
       "1        0.000639        0.016472         0.005916  \n",
       "2        0.000034        0.016801         0.007048  \n",
       "3        0.000283        0.017103         0.007004  \n",
       "4        0.000020        0.016473         0.005942  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "cv_results = pd.DataFrame(grid.cv_results_)\n",
    "cv_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.753177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.713216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.674998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.672333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.636964</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_C param_gamma  mean_test_score\n",
       "19      10           1         0.753177\n",
       "15       1           1         0.713216\n",
       "14       1         0.1         0.674998\n",
       "18      10         0.1         0.672333\n",
       "17      10        0.01         0.636964"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results_tiny = cv_results[['param_C', 'param_gamma', 'mean_test_score']]\n",
    "cv_results_tiny.sort_values(by='mean_test_score', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a problem with using this score for evaluation, however. You might be making what is called a multiple hypothesis testing error. If you try very many parameter settings, some of them will work better just by chance, and the score that you obtained might not reflect how your model would perform on new unseen data.\n",
    "Therefore, it is good to split off a separate test-set before performing grid-search. This pattern can be seen as a training-validation-test split, and is common in machine learning:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/grid_search_cross_validation.svg\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do this very easily by splitting of some test data using ``train_test_split``, training ``GridSearchCV`` on the training set, and applying the ``score`` method to the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7262035177984737"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10], 'gamma': [0.001, 0.01, 0.1, 1]}\n",
    "cv = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "grid = GridSearchCV(SVR(), param_grid=param_grid, cv=cv)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "grid.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at the parameters that were selected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10, 'gamma': 1}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some practitioners go for an easier scheme, splitting the data simply into three parts, training, validation and testing. This is a possible alternative if your training set is very large, or it is infeasible to train many models using cross-validation because training a model takes very long.\n",
    "You can do this with scikit-learn for example by splitting of a test-set and then applying GridSearchCV with ShuffleSplit cross-validation with a single iteration:\n",
    "\n",
    "<img src=\"figures/train_validation_test2.svg\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 20 candidates, totalling 20 fits\n",
      "[CV] C=0.001, gamma=0.001 ............................................\n",
      "[CV]  C=0.001, gamma=0.001, score=-0.007214362798584783, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.01 .............................................\n",
      "[CV] .. C=0.001, gamma=0.01, score=-0.00490525795350405, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.1 ..............................................\n",
      "[CV] ... C=0.001, gamma=0.1, score=0.006532231053487435, total=   0.0s\n",
      "[CV] C=0.001, gamma=1 ................................................\n",
      "[CV] ..... C=0.001, gamma=1, score=0.005181103751859095, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.001 .............................................\n",
      "[CV] . C=0.01, gamma=0.001, score=-0.004714463075054631, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.01 ..............................................\n",
      "[CV] .... C=0.01, gamma=0.01, score=0.01882989634143517, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.1 ...............................................\n",
      "[CV] ..... C=0.01, gamma=0.1, score=0.12758765272825812, total=   0.0s\n",
      "[CV] C=0.01, gamma=1 .................................................\n",
      "[CV] ....... C=0.01, gamma=1, score=0.11606457398627613, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV] .... C=0.1, gamma=0.001, score=0.02092044332819831, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV] ..... C=0.1, gamma=0.01, score=0.20572643024530046, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV] ....... C=0.1, gamma=0.1, score=0.6143251812902222, total=   0.0s\n",
      "[CV] C=0.1, gamma=1 ..................................................\n",
      "[CV] ......... C=0.1, gamma=1, score=0.5415100749579995, total=   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] ...... C=1, gamma=0.001, score=0.20811017285988642, total=   0.0s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] ......... C=1, gamma=0.01, score=0.720843426013521, total=   0.0s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] ......... C=1, gamma=0.1, score=0.8480667153079604, total=   0.0s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] ........... C=1, gamma=1, score=0.7461880126497337, total=   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ...... C=10, gamma=0.001, score=0.7007628330011118, total=   0.0s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] ....... C=10, gamma=0.01, score=0.7754256036910337, total=   0.0s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] ........ C=10, gamma=0.1, score=0.8220841873074334, total=   0.0s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] .......... C=10, gamma=1, score=0.8221833065131534, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6435453677376706"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, ShuffleSplit\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10], 'gamma': [0.001, 0.01, 0.1, 1]}\n",
    "single_split_cv = ShuffleSplit(n_splits=1)\n",
    "\n",
    "grid = GridSearchCV(SVR(), param_grid=param_grid, cv=single_split_cv, verbose=3)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "grid.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is much faster, but might result in worse hyperparameters and therefore worse results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7262035177984737"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GridSearchCV(SVR(), param_grid=param_grid)\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
